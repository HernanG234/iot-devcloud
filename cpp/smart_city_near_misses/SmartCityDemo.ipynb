{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart City - Near Misses Sample\n",
    "\n",
    "This sample showcases Object Detection task applied for vehicles and pedestrians recognition using sequence of neural networks.\n",
    "Async API usage can improve overall frame-rate of the application, because rather than wait for inference to complete, the application can continue operating on the host while accelerator is busy.\n",
    "\n",
    "This project consists on showcasing the advantages of the Intel’s OpenVINO toolkit. We will develop a Near Misses case scenario, where we will detect vehicles and pedestrians, track them across the video and estimate a metric of a crossroad’s dangerousness, based on proximity and sudden acceleration changes.\n",
    "\n",
    "Other sample objectives are:\n",
    "\n",
    "*\tVideo as input support via OpenCV\n",
    "*\tVisualization of the resulting vehicle and pedestrian bounding boxes from Vehicle and Pedestrian Detection network\n",
    "*\tVisualization of trajectory, speed and acceleration of every tracked object.\n",
    "*\tVisualization of near misses and collisions between vehicles.\n",
    "*\tProvide support for General Object Detection network as it is yolo-v3.\n",
    "\n",
    "\n",
    "## How it Works\n",
    "\n",
    "*\tThe application reads command line parameters and loads up to two networks depending on `-m...` options family to the Inference Engine.\n",
    "*\tThe application gets a frame (or batch of frames) from the OpenCV's VideoCapture.\n",
    "*\tThe application performs inference on the frame detection network.\n",
    "*\tThe application performs up to 2 simultaneous inferences, using the Vehicle and Pedestrian detection networks,  if they are specified in command line.\n",
    "*\tThe application displays the results.\n",
    "\n",
    "The new Async API operates with a new notion of the Infer Request that encapsulates the inputs/outputs and separates scheduling and waiting for result. For more information about Async API and the difference between Sync and Async modes performance, refer to **How it Works** and **Async API** sections in [Object Detection SSD, Async API Performance Showcase Sample](@ref InferenceEngineObjectDetectionSSDDemoAsyncApplication).\n",
    "\n",
    "\n",
    "## Compiling\n",
    "\n",
    "There are several source files in the `src/` directory: \n",
    "\n",
    "We have provided a CMakeLists file for compiling the application. Run the following cell to run the make command.\n",
    "It's important to source the setupenv.sh file as it defines some env variables that enable compiling the sample for different OpenVINO versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path().resolve().parent.parent))\n",
    "from demoTools.demoutils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir build && cd build && . ../scripts/setupenv.sh && cmake .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd build && . ../scripts/setupenv.sh && make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This produces an executable [smart_city_tutorial]() in `build/intel64/Release/`. This executable takes in a number of different command line arguments. First, We copy it on the root directory to simplify the next commands.\n",
    "\n",
    "Run the following cell to see the list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp build/intel64/Release/smart_city_tutorial ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/data/reference-sample-data/extension/ \n",
    "./smart_city_tutorial -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The version of the cpp file here is a slightly modified version of the smart_city_tutorial code in the original [**repo**](https://github.com/incluit/OpenVino-For-SmartCity).\n",
    "In this version, the result is written into a output mp4 file if the `-o` flag is specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the inference\n",
    "\n",
    "Now we are ready to run the inference workload. In this step we will be submitting the workload as a job to the job queue.\n",
    "\n",
    "Currently, you are on what is called a \"devnode\". On this system, you are allocated just one core on a large Intel® Xeon® CPU. The purpose of this node is to develop code on the devnode and run minimal sections of Jupyter* Notebooks, but it is not meant for compute intensive jobs like deep learning inference. So we need to request additional resources from the cluster of Edge nodes to run the inference, and this is done through the job queue.\n",
    "\n",
    "To put an item on the job queue, we must first create a bash script that run the workload we want. Run the following cell to create bash script [smart_city_demo.sh](smart_city_demo.sh) which will be our job script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile smart_city_demo.sh\n",
    "#PBS\n",
    "DEVICE=$1\n",
    "FP_MODEL=$2\n",
    "VIDEO_INPUT=$3\n",
    "OUTPUT_PATH=$4\n",
    "\n",
    "if [ \"$1\" = \"HETERO:FPGA,CPU\" ]; then\n",
    "    # Environment variables and compilation for edge compute nodes with FPGAs\n",
    "    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/opt/altera/aocl-pro-rte/aclrte-linux64/\n",
    "    source /opt/fpga_support_files/setup_env.sh\n",
    "    aocl program acl0 /opt/intel/computer_vision_sdk/bitstreams/a10_vision_design_bitstreams/5-0_PL1_FP11_ResNet.aocx\n",
    "fi\n",
    "\n",
    "cd $PBS_O_WORKDIR\n",
    "export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/build/intel64/Release/lib/ \n",
    "MODEL_ROOT=/opt/intel/computer_vision_sdk/deployment_tools/intel_models\n",
    "source scripts/setupenv.sh && ./smart_city_tutorial -i data/$VIDEO_INPUT \\\n",
    "-m_vp $MODEL_ROOT/person-vehicle-bike-detection-crossroad-0078/$FP_MODEL/person-vehicle-bike-detection-crossroad-0078.xml \\\n",
    "-d_vp $DEVICE -tracking -collision -o $OUTPUT_PATH -no_show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put this script on the job queue, we use the command `qsub`.\n",
    "There are two important arguments we use with this command.\n",
    "\n",
    "First, the `-l` flag.\n",
    "This flag is used to specify what type of resources to request from the cluster.\n",
    "For example this can be used to request an Intel® Xeon® CPU based system, or it can be used to request a system with an FPGA accelerator card in it.\n",
    "The syntax is `-l nodes=1:<tag>` where `<tag>` is the descriptor tag for the resource you want.\n",
    "For example, `-l nodes=1:iei-tank-xeon` will request an Intel® Xeon® system.\n",
    "To see the list of available tags, and the number of avilable systems, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pbsnodes | grep compnode | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then there is the `-F` flag, which is used to pass in arguments to the job script.\n",
    "The [smart_city_demo.sh](smart_city_demo.sh) takes in 4 arguments:\n",
    "\n",
    "* 1) the path to the video to run inference on\n",
    "* 2) targeted device (CPU,GPU,MYRIAD)\n",
    "* 3) Single-or-Half-precision floating-point format (FP16, FP32)\n",
    "* 4) Output directory\n",
    "\n",
    "The job scheduler will use the contents of `-F` flag as the argument to the job script.\n",
    "\n",
    "The following line will request an Intel Xeon system, and passes in \"CPU FP32 data/video1.mp4 results/\" to the job script. Run the cell to submit this job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p results\n",
    "os.environ[\"VIDEO_INPUT\"] = \"video1.mp4\"\n",
    "#os.environ[\"VIDEO\"] = \"video2.mp4\"\n",
    "#os.environ[\"VIDEO\"] = \"video3.mp4\"\n",
    "# video3 works much better (but slower) with the yolo network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples**\n",
    "\n",
    "**Tracking:**\n",
    "![tracking](images/tracking2.gif \"tracking\")\n",
    "**Collision:**\n",
    "![collision](images/collision.gif \"collision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with an Intel® Core™ CPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a \n",
    "    href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel \n",
    "    Core i5-6500TE</a>. The inference workload will run on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to Intel Core CPU...\")\n",
    "#Submit job to the queue\n",
    "job_id_core = !qsub smart_city_demo.sh -l nodes=1:tank-870:i5-6500te -F \"CPU FP32 $VIDEO_INPUT results/\"\n",
    "print(job_id_core[0])\n",
    "\n",
    "#Progress indicators\n",
    "if job_id_core:\n",
    "    progressIndicator('results/', 'i_progress_'+job_id_core[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with Intel® Xeon® CPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a \n",
    "    href=\"https://ark.intel.com/products/88178/Intel-Xeon-Processor-E3-1268L-v5-8M-Cache-2-40-GHz-\">Intel \n",
    "    Xeon Processor E3-1268L v5</a>. The inference workload will run on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to Intel Xeon CPU...\")\n",
    "#Submit job to the queue\n",
    "job_id_xeon = !qsub smart_city_demo.sh -l nodes=1:tank-870:e3-1268l-v5 -F \"CPU FP32 $VIDEO_INPUT results/\"\n",
    "print(job_id_xeon[0])\n",
    "\n",
    "#Progress indicators\n",
    "if job_id_xeon:\n",
    "    progressIndicator('results/', 'i_progress_'+job_id_xeon[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you should see a output like \"{job_id}.c003\", where {job_id} is a number.\n",
    "This is your job ID, and this value can be used to check on the progress of the job down the line.\n",
    "Furthermore, the above job script has been written so that it uses its job_id as the name of the output video.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One bigadvantage of the Job queue system is that you may submit multiple jobs at once. \n",
    "These jobs will be run as soon as resources are available, and may all run at once if the cluster is not busy.\n",
    "Here are few other \"preset\" jobs that for your convenience that you can run. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with Intel® Core™ CPU and using the onboard Intel GPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel Core i5-6500TE</a>. The inference workload will run on the Intel® HD Graphics 530 card integrated with the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to Intel Core CPU with Intel GPU...\")\n",
    "#Submit job to the queue\n",
    "job_id_gpu = !qsub smart_city_demo.sh -l nodes=1:tank-870:i5-6500te -F \"GPU FP32 $VIDEO_INPUT results\"\n",
    "print(job_id_gpu[0])\n",
    "\n",
    "#Progress indicators\n",
    "if job_id_gpu:\n",
    "    progressIndicator('results/', 'i_progress_'+job_id_gpu[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with  IEI Mustang-F100-A10 (Intel® Arria® 10 FPGA)\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel Core i5-6500te CPU</a> . The inference workload will run on the <a href=\"https://www.ieiworld.com/mustang-f100/en/\"> IEI Mustang-F100-A10 </a> card installed in this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Submitting job to node with Intel FPGA HDDL-F...\")\n",
    "#Submit job to the queue\n",
    "#job_id_fpga = !qsub smart_city_demo.sh -l nodes=1:tank-870:i5-6500te:iei-mustang-f100-a10 -F \"HETERO:FPGA,CPU FP32 $VIDEO_INPUT results/\"\n",
    "#print(job_id_fpga[0])\n",
    "\n",
    "#Progress indicators\n",
    "#if job_id_fpga:\n",
    "#    progressIndicator('results/', 'i_progress_'+job_id_fpga[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with Intel® Movidius™ Neural Compute Stick\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel Core i5-6500te CPU</a>. The inference workload will run on an <a \n",
    "    href=\"https://software.intel.com/en-us/movidius-ncs\">Intel \n",
    "    Movidius Neural Compute Stick</a> installed in this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to node with Intel Movidius NCS...\")\n",
    "#Submit job to the queue\n",
    "job_id_ncs = !qsub smart_city_demo.sh -l nodes=1:tank-870:i5-6500te:intel-ncs -F \"MYRIAD FP16 $VIDEO_INPUT results/\"\n",
    "print(job_id_ncs[0])\n",
    "\n",
    "#Progress indicators\n",
    "if job_id_ncs:\n",
    "    progressIndicator('results/', 'i_progress_'+job_id_ncs[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with Intel® Movidius™ Neural Compute Stick 2\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel Core i5-6500te CPU</a>. The inference workload will run on an <a \n",
    "    href=\"https://software.intel.com/en-us/neural-compute-stick\">Intel Neural Compute Stick 2</a> installed in this  node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to node with Intel NCS2...\")\n",
    "#Submit job to the queue\n",
    "job_id_ncs2 = !qsub smart_city_demo.sh -l nodes=1:tank-870:i5-6500te:intel-ncs2 -F \"MYRIAD FP16 $VIDEO_INPUT results/\"\n",
    "print(job_id_ncs2[0])\n",
    "\n",
    "#Progress indicators\n",
    "if job_id_ncs2:\n",
    "    progressIndicator('results/', 'i_progress_'+job_id_ncs2[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with  IEI Mustang-V100-MX8 ( Intel® Movidius™ Myriad™ X Vision Processing Unit (VPU))\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel Core i5-6500te CPU</a>. The inference workload will run on an <a \n",
    "    href=\"https://www.ieiworld.com/mustang-v100/en/\">IEI Mustang-V100-MX8 </a>accelerator installed in this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit job to the queue\n",
    "job_id_vpu = !qsub smart_city_demo.sh -l nodes=1:tank-870:i5-6500te:iei-mustang-v100-mx8 -F \"HDDL FP16 $VIDEO_INPUT results/\"\n",
    "print(job_id_vpu[0])\n",
    "\n",
    "#Progress indicators\n",
    "if job_id_vpu:\n",
    "    progressIndicator('results/', 'i_progress_'+job_id_vpu[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting to an edge compute node with UP Squared Grove IoT Development Kit (UP2)\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/up-squared-grove-dev-kit\">UP Squared Grove IoT Development Kit</a> edge node with an <a \n",
    "    href=\"https://ark.intel.com/products/96488/Intel-Atom-x7-E3950-Processor-2M-Cache-up-to-2-00-GHz-\">Intel Atom® x7-E3950 Processor</a>. The inference  workload will run on the integrated Intel® HD Graphics 505 card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit job to the queue\n",
    "#job_id_up2 = !qsub smart_city_atom.sh -l nodes=1:up-squared -F \"GPU FP32 $VIDEO_INPUT results/\"\n",
    "#print(job_id_up2[0])\n",
    "\n",
    "#Progress indicators\n",
    "#if job_id_up2:\n",
    "#    progressIndicator('results/', 'i_progress_'+job_id_up2[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `qstat` command is used to track the progress of the jobs. \n",
    "We have provided a utility funtion \"liveQstat()\" that provide a live updating GUI for you.\n",
    "Run the following cell to check on the progress of your earlier jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liveQstat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the jobs are done. The following cell can be used to display the output. \n",
    "The videoHTML is a utility function provided in [demoutils.py](demoutils.py).\n",
    "This takes one argument, which is the path to the video (see above for convention for the path name).\n",
    "\n",
    "For your convenience we have stored the jobid from the above `qsub` commands, and the following cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('IEI Tank (Intel Core CPU)', \n",
    "          ['results/output_' + job_id_core[0] + '.mp4'], \n",
    "          'results/stats_'+job_id_core[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('IEI Tank Xeon (Intel Xeon CPU)',\n",
    "          ['results/output_'+job_id_xeon[0]+'.mp4'],\n",
    "          'results/stats_'+job_id_xeon[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('IEI Intel GPU (Intel Core + Onboard GPU)', \n",
    "          ['results/output_'+job_id_gpu[0]+'.mp4'],\n",
    "          'results/stats_'+job_id_gpu[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#videoHTML('IEI Tank + IEI Mustang-F100-A10 (Intel® Arria® 10 FPGA)',\n",
    "#          ['results/output_'+job_id_fpga[0]+'.mp4'],\n",
    "#          'results/stats_'+job_id_fpga[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('IEI Tank + Intel CPU + Intel Movidius NCS',\n",
    "          ['results/output_'+job_id_ncs[0]+'.mp4'],\n",
    "          'results/stats_'+job_id_ncs[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('IEI Tank + Intel CPU + Intel NCS2',\n",
    "          ['results/output_'+job_id_ncs2[0]+'.mp4'],\n",
    "          'results/stats_'+job_id_ncs2[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('IEI Tank + IEI Mustang-V100-MX8 (Intel® Movidius™ Myriad™ X Vision Processing Unit (VPU))',\n",
    "          ['results/output_'+job_id_vpu[0]+'.mp4'],\n",
    "          'results/stats_'+job_id_vpu[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#videoHTML('UP Squared Grove IoT Development Kit (UP2)',\n",
    "#          ['results/output_'+job_id_up2[0]+'.mp4'],\n",
    "#          'results/stats_'+job_id_up2[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_list = [('core', 'Intel Core\\ni5-6500TE\\nCPU'),\n",
    "             ('xeon', 'Intel Xeon\\nE3-1268L v5\\nCPU'),\n",
    "             ('gpu', ' Intel Core\\ni5-6500TE\\nGPU'),\n",
    "      #       ('fpga', ' IEI Mustang\\nF100-A10\\nFPGA'),\n",
    "             ('ncs', 'Intel\\nMovidius\\nNCS'),\n",
    "             ('ncs2', 'Intel\\nNCS2'),\n",
    "             ('vpu', ' IEI Mustang\\nV100-MX8\\nVPU')]\n",
    "      #      ('up2', 'Intel Atom\\nx7-E3950\\nUP2/GPU')]\n",
    "\n",
    "stats_list = []\n",
    "for arch, a_name in arch_list:\n",
    "    if 'job_id_'+arch in vars():\n",
    "        stats_list.append(('results/stats_'+vars()['job_id_'+arch][0]+'.txt', a_name))\n",
    "    else:\n",
    "        stats_list.append(('placeholder'+arch, a_name))\n",
    "\n",
    "summaryPlot(stats_list, 'Architecture', 'Time, seconds', 'Inference Engine Processing Time', 'time' )\n",
    "summaryPlot(stats_list, 'Architecture', 'Frames per second', 'Inference Engine FPS', 'fps' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu)",
   "language": "python",
   "name": "c003-python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
